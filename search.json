[
  {
    "objectID": "modelos_regresion.html",
    "href": "modelos_regresion.html",
    "title": "Modelos de Regresión en R",
    "section": "",
    "text": "Introducción\nEste documento presenta diferentes modelos de regresión aplicados a los conjuntos de datos Boston y Hitters, usando regresión lineal, regresión múltiple, modelos con interacción, modelos polinomiales, y regularización (Ridge y Lasso). Se incluyen interpretaciones de los resultados y visualizaciones, incluyendo una gráfica 3D.\n\n# Cargamos paquetes necesarios\nlibrary(MASS)\nlibrary(car)\n\nWarning: package 'car' was built under R version 4.4.2\n\n\nCargando paquete requerido: carData\n\nlibrary(rgl)\nlibrary(ISLR)\nlibrary(glmnet)\n\nCargando paquete requerido: Matrix\n\n\nLoaded glmnet 4.1-8\n\nlibrary(quarto)\n\nWarning: package 'quarto' was built under R version 4.4.3\n\n\n\n\nRegresión Lineal Simple\nUtilizamos el conjunto de datos Boston para predecir el valor medio de las viviendas (medv) a partir del porcentaje de población con bajos ingresos (lstat).\n\n# Observamos las variables de la tabla de datos Boston, y la ayuda\nnames(Boston) #para visualizar los nombres\n\n [1] \"crim\"    \"zn\"      \"indus\"   \"chas\"    \"nox\"     \"rm\"      \"age\"    \n [8] \"dis\"     \"rad\"     \"tax\"     \"ptratio\" \"black\"   \"lstat\"   \"medv\"   \n\n?Boston    #para visualizar los datos de Boston\n\nstarting httpd help server ... done\n\n# Regresion lineal simple\n\nmodelo&lt;-lm(medv~lstat, data=Boston)  #medv registra el precio medio del valor de una casa en dolares\n                                    #lm= lineal model \n\nplot(Boston$lstat,Boston$medv);    #Plot para pintar el diagrama de dispersion de estas dos variables\nabline(modelo,lwd=3,col=\"blue\")#Pinta una recta b=pendiente a= punto\n\n\n\n\n\n\n\nsummary(modelo)   #estimate std son los beta gorro, error estandar es la desviacion, el valor t, estadistico, desviacion tipica residual\n\n\nCall:\nlm(formula = medv ~ lstat, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.168  -3.990  -1.318   2.034  24.500 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 34.55384    0.56263   61.41   &lt;2e-16 ***\nlstat       -0.95005    0.03873  -24.53   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.216 on 504 degrees of freedom\nMultiple R-squared:  0.5441,    Adjusted R-squared:  0.5432 \nF-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16\n\nnames(modelo)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\nconfint(modelo,level=0.95)\n\n                2.5 %     97.5 %\n(Intercept) 33.448457 35.6592247\nlstat       -1.026148 -0.8739505\n\nnuevos&lt;-data.frame(lstat=c(5,10,15))\npredict(modelo,nuevos,interval=\"prediction\") #predecir\n\n       fit       lwr      upr\n1 29.80359 17.565675 42.04151\n2 25.05335 12.827626 37.27907\n3 20.30310  8.077742 32.52846\n\nplot(modelo)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretación:\nEl coeficiente negativo de lstat indica que a mayor porcentaje de población con bajos ingresos, menor es el valor medio de las viviendas. El modelo tiene una relación lineal negativa clara y significativa.\n\n\nRegresión Lineal Múltiple\nAñadimos más predictores como age y todas las variables disponibles en el conjunto.\n\nmodelo2 &lt;- lm(medv ~ lstat + age, data = Boston)\nmodelo3 &lt;- lm(medv ~ ., data = Boston)\nsummary(modelo2)\n\n\nCall:\nlm(formula = medv ~ lstat + age, data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.981  -3.978  -1.283   1.968  23.158 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 33.22276    0.73085  45.458  &lt; 2e-16 ***\nlstat       -1.03207    0.04819 -21.416  &lt; 2e-16 ***\nage          0.03454    0.01223   2.826  0.00491 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.173 on 503 degrees of freedom\nMultiple R-squared:  0.5513,    Adjusted R-squared:  0.5495 \nF-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16\n\nsummary(modelo3)\n\n\nCall:\nlm(formula = medv ~ ., data = Boston)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-15.595  -2.730  -0.518   1.777  26.199 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.646e+01  5.103e+00   7.144 3.28e-12 ***\ncrim        -1.080e-01  3.286e-02  -3.287 0.001087 ** \nzn           4.642e-02  1.373e-02   3.382 0.000778 ***\nindus        2.056e-02  6.150e-02   0.334 0.738288    \nchas         2.687e+00  8.616e-01   3.118 0.001925 ** \nnox         -1.777e+01  3.820e+00  -4.651 4.25e-06 ***\nrm           3.810e+00  4.179e-01   9.116  &lt; 2e-16 ***\nage          6.922e-04  1.321e-02   0.052 0.958229    \ndis         -1.476e+00  1.995e-01  -7.398 6.01e-13 ***\nrad          3.060e-01  6.635e-02   4.613 5.07e-06 ***\ntax         -1.233e-02  3.760e-03  -3.280 0.001112 ** \nptratio     -9.527e-01  1.308e-01  -7.283 1.31e-12 ***\nblack        9.312e-03  2.686e-03   3.467 0.000573 ***\nlstat       -5.248e-01  5.072e-02 -10.347  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.745 on 492 degrees of freedom\nMultiple R-squared:  0.7406,    Adjusted R-squared:  0.7338 \nF-statistic: 108.1 on 13 and 492 DF,  p-value: &lt; 2.2e-16\n\nvif(modelo3)\n\n    crim       zn    indus     chas      nox       rm      age      dis \n1.792192 2.298758 3.991596 1.073995 4.393720 1.933744 3.100826 3.955945 \n     rad      tax  ptratio    black    lstat \n7.484496 9.008554 1.799084 1.348521 2.941491 \n\n\nInterpretación:\nEl modelo múltiple mejora la explicación del valor de medv. Algunos predictores como rm (número de habitaciones) y lstat siguen siendo muy significativos. El VIF permite identificar colinealidad.\n\n\nModelo con Interacción\n\nmodelo5 &lt;- lm(medv ~ lstat * rm, data = Boston)\nsummary(modelo5)\n\n\nCall:\nlm(formula = medv ~ lstat * rm, data = Boston)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-23.2349  -2.6897  -0.6158   1.9663  31.6141 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -29.12452    3.34250  -8.713   &lt;2e-16 ***\nlstat         2.19398    0.20570  10.666   &lt;2e-16 ***\nrm            9.70126    0.50023  19.393   &lt;2e-16 ***\nlstat:rm     -0.48494    0.03459 -14.018   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.701 on 502 degrees of freedom\nMultiple R-squared:  0.7402,    Adjusted R-squared:  0.7387 \nF-statistic: 476.9 on 3 and 502 DF,  p-value: &lt; 2.2e-16\n\n\nInterpretación:\nEl término de interacción lstat:rm muestra que el efecto de lstat sobre medv cambia dependiendo del valor de rm. Esto añade complejidad y mejora la interpretación del modelo.\n\n\nVisualización 3D de Interacción\n\n# Preparar datos para graficar en 3D\nx &lt;- Boston$lstat\ny &lt;- Boston$rm\nz &lt;- Boston$medv\nmodelo_inter &lt;- lm(medv ~ lstat * rm, data = Boston)\ngrid &lt;- expand.grid(\n  lstat = seq(min(x), max(x), length.out = 30),\n  rm = seq(min(y), max(y), length.out = 30)\n)\ngrid$medv &lt;- predict(modelo_inter, newdata = grid)\n\n# Gráfica 3D\nplot3d(x, y, z, col = \"red\", size = 5, xlab = \"lstat\", ylab = \"rm\", zlab = \"medv\")\nsurface3d(unique(grid$lstat), unique(grid$rm), matrix(grid$medv, 30, 30), alpha = 0.5, front = \"lines\")\n\nInterpretación:\nLa gráfica 3D muestra cómo se combinan lstat y rm para explicar medv. Permite visualizar mejor la interacción entre variables.\n\n\nRegularización: Ridge y Lasso\nUsamos el conjunto Hitters para aplicar técnicas de regularización.\n\nbateadores&lt;-na.omit(Hitters)\n\nx&lt;-model.matrix(Salary~.,data=bateadores)[,-1]\ny&lt;-bateadores$Salary\n\n\nset.seed(123)  # reproducibilidad\ntrain &lt;- sample(1:nrow(x), nrow(x) * 0.7)\ntest &lt;- (-train)\n\nx_train &lt;- x[train, ]\ny_train &lt;- y[train]\nx_test &lt;- x[test, ]\ny_test &lt;- y[test]\n\n# Ridge\ncv_ridge &lt;- cv.glmnet(x_train, y_train, alpha = 0)\nbest_lambda_ridge &lt;- cv_ridge$lambda.min\n\n# Lasso\ncv_lasso &lt;- cv.glmnet(x_train, y_train, alpha = 1)\nbest_lambda_lasso &lt;- cv_lasso$lambda.min\n\n# Predicciones\nridge_pred &lt;- predict(cv_ridge, s = best_lambda_ridge, newx = x_test)\nlasso_pred &lt;- predict(cv_lasso, s = best_lambda_lasso, newx = x_test)\n\n# Error cuadrático medio (RMSE)\nrmse &lt;- function(actual, predicted) {\n  sqrt(mean((actual - predicted)^2))\n}\n\nridge_rmse &lt;- rmse(y_test, ridge_pred)\nlasso_rmse &lt;- rmse(y_test, lasso_pred)\n\ncat(\"RMSE Ridge:\", ridge_rmse, \"\\n\")\n\nRMSE Ridge: 340.2387 \n\ncat(\"RMSE Lasso:\", lasso_rmse, \"\\n\")\n\nRMSE Lasso: 353.427 \n\ncoef(cv_ridge, s = best_lambda_ridge)\n\n20 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  1.455233e+02\nAtBat       -7.030774e-01\nHits         2.021293e+00\nHmRun       -5.249070e+00\nRuns         1.570071e+00\nRBI          1.379935e+00\nWalks        4.323138e+00\nYears       -2.230570e+01\nCAtBat      -4.235889e-03\nCHits        1.576739e-01\nCHmRun       1.347240e+00\nCRuns        4.494777e-01\nCRBI         2.728603e-01\nCWalks      -2.950156e-01\nLeagueN      2.865266e+01\nDivisionW   -1.383327e+02\nPutOuts      1.660888e-01\nAssists      2.865332e-01\nErrors      -6.513609e+00\nNewLeagueN   5.494518e+01\n\ncoef(cv_lasso, s = best_lambda_lasso)\n\n20 x 1 sparse Matrix of class \"dgCMatrix\"\n                       s1\n(Intercept)  2.243591e+02\nAtBat       -1.736536e+00\nHits         4.887216e+00\nHmRun       -4.651302e+00\nRuns         .           \nRBI          1.649534e+00\nWalks        6.233259e+00\nYears       -2.747691e+01\nCAtBat      -2.457637e-04\nCHits        .           \nCHmRun       1.754708e+00\nCRuns        1.259449e+00\nCRBI         8.816749e-02\nCWalks      -7.608609e-01\nLeagueN      9.577020e+00\nDivisionW   -1.299548e+02\nPutOuts      1.963603e-01\nAssists      3.982851e-01\nErrors      -7.307900e+00\nNewLeagueN   7.456114e+01\n\nplot(cv_ridge)\n\n\n\n\n\n\n\nplot(cv_lasso)\n\n\n\n\n\n\n\n\nInterpretación:\n- Ridge reduce el tamaño de los coeficientes, útil si hay multicolinealidad. - Lasso además puede eliminar variables irrelevantes, haciendo selección automática.\n\nLasso ha eliminado algunas variables que no ayudan mucho a predecir el salario (Runs, CHits).\nAlgunas variables con signos negativos inesperados podrían deberse a multicolinealidad o interacciones con otras variables similares (ej. HmRun negativo pero CHmRun positivo).\nVariables como DivisionW, NewLeagueN, y LeagueN muestran cómo factores de contexto también afectan el salario.\n\n\nEste documento demuestra habilidades en regresión, análisis gráfico, interpretación y uso de técnicas modernas como la regularización. También destaca el uso de herramientas visuales como rgl para análisis tridimensional."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portafolio R",
    "section": "",
    "text": "Hola, mi nombre es Walls Salcedo Carlos y soy estudiante de último semestre de la Licenciatura en Actuaría. Este portafolio reúne algunos de los trabajos que he realizado durante mi carrera, así como proyectos personales y ejercicios desarrollados en cursos externos como:\n\nAdvanced Data Analytics (Google)\nProyectos de análisis estadístico\nModelos predictivos y de regresión\nAplicaciones en R usando Quarto y R Markdown\n\n\n\n\nEste portafolio incluye:\n\nModelos de regresión lineal y múltiple\nModelos con interacción y polinomiales\nVisualizaciones en 2D y 3D\nRegularización (Ridge y Lasso)\nAnálisis exploratorio de datos (EDA)\nLimpieza y preparación de datos\n\n\n\n\n\n\nR y RStudio\nQuarto\nPaquetes: tidyverse, ggplot2, dplyr, glmnet, rgl, etc\n\nGracias por visitar mi portafolio."
  },
  {
    "objectID": "index.html#qué-encontrarás-aquí",
    "href": "index.html#qué-encontrarás-aquí",
    "title": "Portafolio R",
    "section": "",
    "text": "Este portafolio incluye:\n\nModelos de regresión lineal y múltiple\nModelos con interacción y polinomiales\nVisualizaciones en 2D y 3D\nRegularización (Ridge y Lasso)\nAnálisis exploratorio de datos (EDA)\nLimpieza y preparación de datos"
  },
  {
    "objectID": "index.html#herramientas-utilizadas",
    "href": "index.html#herramientas-utilizadas",
    "title": "Portafolio R",
    "section": "",
    "text": "R y RStudio\nQuarto\nPaquetes: tidyverse, ggplot2, dplyr, glmnet, rgl, etc\n\nGracias por visitar mi portafolio."
  }
]